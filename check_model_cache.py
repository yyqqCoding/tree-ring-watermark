#!/usr/bin/env python3
"""
æ¨¡å‹ç¼“å­˜æ£€æŸ¥å’Œç®¡ç†å·¥å…·

è¿™ä¸ªè„šæœ¬å¸®åŠ©ä½ ï¼š
1. æŸ¥æ‰¾ Hugging Face æ¨¡å‹çš„ç¼“å­˜ä½ç½®
2. æ˜¾ç¤ºå·²ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶
3. æä¾›ä¸Šä¼ åˆ°æœåŠ¡å™¨çš„æŒ‡å¯¼
4. ç®¡ç†æ¨¡å‹ç¼“å­˜

ä½¿ç”¨æ–¹æ³•:
python check_model_cache.py --model_id runwayml/stable-diffusion-v1-5
"""

import os
import sys
import argparse
import shutil
from pathlib import Path
import json
from typing import List, Dict, Optional

def get_hf_cache_dir() -> str:
    """è·å– Hugging Face ç¼“å­˜ç›®å½•"""
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if 'HF_HOME' in os.environ:
        return os.path.join(os.environ['HF_HOME'], 'hub')
    elif 'HUGGINGFACE_HUB_CACHE' in os.environ:
        return os.environ['HUGGINGFACE_HUB_CACHE']
    else:
        # é»˜è®¤ä½ç½®
        if os.name == 'nt':  # Windows
            cache_dir = os.path.join(os.path.expanduser('~'), '.cache', 'huggingface', 'hub')
        else:  # Linux/Mac
            cache_dir = os.path.join(os.path.expanduser('~'), '.cache', 'huggingface', 'hub')
        return cache_dir

def find_model_cache(model_id: str) -> Optional[str]:
    """æŸ¥æ‰¾ç‰¹å®šæ¨¡å‹çš„ç¼“å­˜ç›®å½•"""
    cache_dir = get_hf_cache_dir()
    
    # å°†æ¨¡å‹IDè½¬æ¢ä¸ºç¼“å­˜ç›®å½•å
    # ä¾‹å¦‚: runwayml/stable-diffusion-v1-5 -> models--runwayml--stable-diffusion-v1-5
    cache_name = f"models--{model_id.replace('/', '--')}"
    model_cache_path = os.path.join(cache_dir, cache_name)
    
    if os.path.exists(model_cache_path):
        return model_cache_path
    else:
        return None

def get_model_files(model_cache_path: str) -> Dict[str, List[str]]:
    """è·å–æ¨¡å‹ç¼“å­˜ç›®å½•ä¸­çš„æ–‡ä»¶åˆ—è¡¨"""
    files_info = {
        'snapshots': [],
        'refs': [],
        'blobs': []
    }
    
    if not os.path.exists(model_cache_path):
        return files_info
    
    # æ£€æŸ¥ snapshots ç›®å½•
    snapshots_dir = os.path.join(model_cache_path, 'snapshots')
    if os.path.exists(snapshots_dir):
        for snapshot in os.listdir(snapshots_dir):
            snapshot_path = os.path.join(snapshots_dir, snapshot)
            if os.path.isdir(snapshot_path):
                files_info['snapshots'].append(snapshot)
    
    # æ£€æŸ¥ refs ç›®å½•
    refs_dir = os.path.join(model_cache_path, 'refs')
    if os.path.exists(refs_dir):
        files_info['refs'] = os.listdir(refs_dir)
    
    # æ£€æŸ¥ blobs ç›®å½•
    blobs_dir = os.path.join(model_cache_path, 'blobs')
    if os.path.exists(blobs_dir):
        files_info['blobs'] = os.listdir(blobs_dir)
    
    return files_info

def calculate_cache_size(model_cache_path: str) -> int:
    """è®¡ç®—æ¨¡å‹ç¼“å­˜çš„æ€»å¤§å°"""
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(model_cache_path):
        for filename in filenames:
            filepath = os.path.join(dirpath, filename)
            if os.path.exists(filepath):
                total_size += os.path.getsize(filepath)
    return total_size

def format_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
    if size_bytes == 0:
        return "0B"
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    return f"{size_bytes:.2f} {size_names[i]}"

def print_model_info(model_id: str):
    """æ‰“å°æ¨¡å‹ç¼“å­˜ä¿¡æ¯"""
    print(f"\n{'='*60}")
    print(f"æ¨¡å‹: {model_id}")
    print(f"{'='*60}")
    
    # æŸ¥æ‰¾ç¼“å­˜ç›®å½•
    cache_path = find_model_cache(model_id)
    if not cache_path:
        print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹ {model_id} çš„ç¼“å­˜")
        print(f"ğŸ’¡ è¯·å…ˆè¿è¡Œè„šæœ¬ä¸‹è½½æ¨¡å‹ï¼Œæˆ–æ£€æŸ¥æ¨¡å‹IDæ˜¯å¦æ­£ç¡®")
        return
    
    print(f"âœ… æ‰¾åˆ°æ¨¡å‹ç¼“å­˜")
    print(f"ğŸ“ ç¼“å­˜è·¯å¾„: {cache_path}")
    
    # è®¡ç®—å¤§å°
    cache_size = calculate_cache_size(cache_path)
    print(f"ğŸ’¾ ç¼“å­˜å¤§å°: {format_size(cache_size)}")
    
    # è·å–æ–‡ä»¶ä¿¡æ¯
    files_info = get_model_files(cache_path)
    
    print(f"\nğŸ“‹ ç¼“å­˜å†…å®¹:")
    print(f"  - Snapshots: {len(files_info['snapshots'])} ä¸ª")
    print(f"  - Refs: {len(files_info['refs'])} ä¸ª")
    print(f"  - Blobs: {len(files_info['blobs'])} ä¸ª")
    
    # æ˜¾ç¤ºæœ€æ–°çš„ snapshot
    if files_info['snapshots']:
        latest_snapshot = max(files_info['snapshots'])
        snapshot_path = os.path.join(cache_path, 'snapshots', latest_snapshot)
        print(f"\nğŸ“‚ æœ€æ–° Snapshot: {latest_snapshot}")
        print(f"   è·¯å¾„: {snapshot_path}")
        
        # åˆ—å‡º snapshot ä¸­çš„æ–‡ä»¶
        if os.path.exists(snapshot_path):
            snapshot_files = []
            for root, dirs, files in os.walk(snapshot_path):
                for file in files:
                    rel_path = os.path.relpath(os.path.join(root, file), snapshot_path)
                    file_size = os.path.getsize(os.path.join(root, file))
                    snapshot_files.append((rel_path, file_size))
            
            print(f"   åŒ…å« {len(snapshot_files)} ä¸ªæ–‡ä»¶:")
            for file_path, file_size in sorted(snapshot_files):
                print(f"     - {file_path} ({format_size(file_size)})")

def print_upload_instructions(model_id: str):
    """æ‰“å°ä¸Šä¼ åˆ°æœåŠ¡å™¨çš„è¯´æ˜"""
    cache_path = find_model_cache(model_id)
    if not cache_path:
        print("âŒ æœªæ‰¾åˆ°æ¨¡å‹ç¼“å­˜ï¼Œæ— æ³•æä¾›ä¸Šä¼ è¯´æ˜")
        return
    
    print(f"\n{'='*60}")
    print("ğŸ“¤ ä¸Šä¼ åˆ°æœåŠ¡å™¨çš„è¯´æ˜")
    print(f"{'='*60}")
    
    print("1. å‹ç¼©æ¨¡å‹ç¼“å­˜:")
    cache_name = os.path.basename(cache_path)
    print(f"   cd {os.path.dirname(cache_path)}")
    print(f"   tar -czf {cache_name}.tar.gz {cache_name}")
    
    print("\n2. ä¸Šä¼ åˆ°æœåŠ¡å™¨:")
    print(f"   scp {cache_name}.tar.gz user@server:/path/to/server/")
    
    print("\n3. åœ¨æœåŠ¡å™¨ä¸Šè§£å‹:")
    server_cache_dir = "~/.cache/huggingface/hub"
    print(f"   cd {server_cache_dir}")
    print(f"   tar -xzf {cache_name}.tar.gz")
    
    print("\n4. éªŒè¯:")
    print(f"   ls -la {server_cache_dir}/{cache_name}")
    
    print(f"\nğŸ’¡ æç¤º:")
    print(f"   - æœåŠ¡å™¨ä¸Šçš„ç¼“å­˜ç›®å½•é€šå¸¸æ˜¯: ~/.cache/huggingface/hub")
    print(f"   - å¦‚æœæœåŠ¡å™¨ä½¿ç”¨ä¸åŒçš„ç¼“å­˜ç›®å½•ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡:")
    print(f"     export HF_HOME=/your/custom/cache/dir")
    print(f"   - ç¡®ä¿æœåŠ¡å™¨ä¸Šæœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ ({format_size(calculate_cache_size(cache_path))})")

def main():
    parser = argparse.ArgumentParser(description="æ£€æŸ¥å’Œç®¡ç† Hugging Face æ¨¡å‹ç¼“å­˜")
    parser.add_argument("--model_id", default="runwayml/stable-diffusion-v1-5", 
                       help="æ¨¡å‹ID (é»˜è®¤: runwayml/stable-diffusion-v1-5)")
    parser.add_argument("--list_all", action="store_true", 
                       help="åˆ—å‡ºæ‰€æœ‰ç¼“å­˜çš„æ¨¡å‹")
    parser.add_argument("--cache_dir", action="store_true", 
                       help="æ˜¾ç¤ºç¼“å­˜ç›®å½•ä½ç½®")
    
    args = parser.parse_args()
    
    if args.cache_dir:
        cache_dir = get_hf_cache_dir()
        print(f"ğŸ—‚ï¸  Hugging Face ç¼“å­˜ç›®å½•: {cache_dir}")
        print(f"ğŸ“Š ç›®å½•æ˜¯å¦å­˜åœ¨: {'âœ…' if os.path.exists(cache_dir) else 'âŒ'}")
        return
    
    if args.list_all:
        cache_dir = get_hf_cache_dir()
        if not os.path.exists(cache_dir):
            print(f"âŒ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
            return
        
        print(f"ğŸ“‹ æ‰€æœ‰ç¼“å­˜çš„æ¨¡å‹:")
        models = [d for d in os.listdir(cache_dir) if d.startswith('models--')]
        if not models:
            print("   (æ— ç¼“å­˜æ¨¡å‹)")
        else:
            for model in sorted(models):
                model_id = model.replace('models--', '').replace('--', '/')
                model_path = os.path.join(cache_dir, model)
                size = calculate_cache_size(model_path)
                print(f"   - {model_id} ({format_size(size)})")
        return
    
    # æ£€æŸ¥ç‰¹å®šæ¨¡å‹
    print_model_info(args.model_id)
    print_upload_instructions(args.model_id)

if __name__ == "__main__":
    main()
